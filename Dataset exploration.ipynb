{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adbf327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325c4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e544e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for filename in os.listdir('data/aclImdb/train/pos'):\n",
    "    with open(os.path.join('data/aclImdb/train/pos', filename)) as f:\n",
    "        sentences.append(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9fda0d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))\n",
    "len_sentences = map( lambda x: len([w for w in nltk.word_tokenize(x[0]) if w not in sw]), sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a14bd4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2056., 3433., 1860., 1196.,  873.,  601.,  436.,  324.,  272.,\n",
       "         199.]),\n",
       " array([ 46. ,  89.5, 133. , 176.5, 220. , 263.5, 307. , 350.5, 394. ,\n",
       "        437.5, 481. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(sentences)\n",
    "plt.hist(sorted(list(len_sentences))[int(0.05*n):int(0.95*n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75cf9480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/gpufs/users/students/iasd22/iasd22_0899/nltk_dat\n",
      "[nltk_data]     a...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "953a32a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Hanson',\n",
       " 'brothers',\n",
       " '-',\n",
       " 'Andy',\n",
       " '(',\n",
       " 'apparently',\n",
       " 'has',\n",
       " 'his',\n",
       " 'act',\n",
       " 'together',\n",
       " ')',\n",
       " 'and',\n",
       " 'Hank',\n",
       " '(',\n",
       " 'clearly',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'have',\n",
       " 'his',\n",
       " 'act',\n",
       " 'together',\n",
       " ')',\n",
       " 'need',\n",
       " 'money',\n",
       " '.',\n",
       " 'Andy',\n",
       " 'comes',\n",
       " 'up',\n",
       " 'with',\n",
       " 'a',\n",
       " 'scheme',\n",
       " 'to',\n",
       " 'get',\n",
       " 'some',\n",
       " 'dough',\n",
       " 'that',\n",
       " 'will',\n",
       " 'have',\n",
       " 'consequences',\n",
       " 'for',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'Hanson',\n",
       " 'family.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'This',\n",
       " 'film',\n",
       " 'delivers',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'layered',\n",
       " ',',\n",
       " 'full-blooded',\n",
       " 'roller',\n",
       " 'coaster',\n",
       " 'ride',\n",
       " 'that',\n",
       " 'knows',\n",
       " 'exactly',\n",
       " 'what',\n",
       " 'it',\n",
       " 'is',\n",
       " 'doing',\n",
       " '.',\n",
       " 'As',\n",
       " 'a',\n",
       " 'crime',\n",
       " 'drama',\n",
       " '/',\n",
       " 'thriller',\n",
       " 'I',\n",
       " 'would',\n",
       " 'happily',\n",
       " 'compare',\n",
       " 'it',\n",
       " 'to',\n",
       " \"'No\",\n",
       " 'Country',\n",
       " 'For',\n",
       " 'Old',\n",
       " 'Men',\n",
       " '.',\n",
       " \"'\",\n",
       " 'While',\n",
       " 'both',\n",
       " 'films',\n",
       " 'have',\n",
       " 'have',\n",
       " 'an',\n",
       " 'ample',\n",
       " 'supply',\n",
       " 'of',\n",
       " 'character',\n",
       " 'drama',\n",
       " 'and',\n",
       " 'thrills',\n",
       " ',',\n",
       " \"'Devil\",\n",
       " \"'\",\n",
       " 'is',\n",
       " 'more',\n",
       " 'on',\n",
       " 'the',\n",
       " 'thriller',\n",
       " 'side',\n",
       " 'because',\n",
       " 'of',\n",
       " 'its',\n",
       " 'fast',\n",
       " 'pace',\n",
       " '.',\n",
       " \"'No\",\n",
       " 'Country',\n",
       " \"'\",\n",
       " 'is',\n",
       " 'a',\n",
       " 'colder',\n",
       " 'and',\n",
       " 'bleaker',\n",
       " 'film',\n",
       " 'that',\n",
       " 'you',\n",
       " 'can',\n",
       " 'really',\n",
       " 'admire',\n",
       " ',',\n",
       " 'while',\n",
       " \"'Devil\",\n",
       " \"'\",\n",
       " 'is',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'more',\n",
       " 'enjoyable',\n",
       " '.',\n",
       " 'There',\n",
       " 'is',\n",
       " 'definitely',\n",
       " 'less',\n",
       " 'violence',\n",
       " 'in',\n",
       " \"'Devil\",\n",
       " \"'\",\n",
       " 'than',\n",
       " \"'No\",\n",
       " 'Country',\n",
       " '.',\n",
       " \"'\",\n",
       " 'The',\n",
       " 'acting',\n",
       " 'delivers',\n",
       " 'as',\n",
       " 'well',\n",
       " '.',\n",
       " 'Ethan',\n",
       " 'Hawke',\n",
       " ',',\n",
       " 'sometimes',\n",
       " 'wooden',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " ',',\n",
       " 'brings',\n",
       " 'the',\n",
       " 'jitters',\n",
       " ',',\n",
       " 'sweating',\n",
       " 'and',\n",
       " 'the',\n",
       " 'deer-in-the-headlights-look',\n",
       " 'to',\n",
       " 'the',\n",
       " 'besieged',\n",
       " 'Hank',\n",
       " '.',\n",
       " 'Philip',\n",
       " 'Seymour',\n",
       " 'Hoffman',\n",
       " ',',\n",
       " 'as',\n",
       " 'Andy',\n",
       " ',',\n",
       " 'has',\n",
       " 'the',\n",
       " 'film',\n",
       " \"'s\",\n",
       " 'hardest',\n",
       " 'scenes',\n",
       " 'and',\n",
       " 'is',\n",
       " 'fast',\n",
       " 'becoming',\n",
       " 'the',\n",
       " 'actor',\n",
       " ',',\n",
       " 'who',\n",
       " 'you',\n",
       " 'believe',\n",
       " 'can',\n",
       " 'do',\n",
       " 'anything.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'There',\n",
       " \"'s\",\n",
       " 'really',\n",
       " 'not',\n",
       " 'much',\n",
       " 'wrong',\n",
       " 'with',\n",
       " 'this',\n",
       " 'film',\n",
       " '.',\n",
       " 'It',\n",
       " 'jumps',\n",
       " 'back',\n",
       " 'and',\n",
       " 'forth',\n",
       " 'without',\n",
       " 'being',\n",
       " 'confusing',\n",
       " '.',\n",
       " 'Events',\n",
       " 'spiral',\n",
       " 'out',\n",
       " 'of',\n",
       " 'control',\n",
       " ',',\n",
       " 'but',\n",
       " 'the',\n",
       " 'film',\n",
       " 'never',\n",
       " 'does',\n",
       " '-',\n",
       " 'the',\n",
       " 'writing',\n",
       " '(',\n",
       " 'from',\n",
       " 'first',\n",
       " 'timer',\n",
       " 'Kelly',\n",
       " 'Masterson',\n",
       " ')',\n",
       " ',',\n",
       " 'directing',\n",
       " '(',\n",
       " 'veteran',\n",
       " 'Sidney',\n",
       " 'Lumet',\n",
       " ')',\n",
       " 'and',\n",
       " 'the',\n",
       " 'editing',\n",
       " 'stay',\n",
       " 'as',\n",
       " 'tight',\n",
       " 'as',\n",
       " 'a',\n",
       " 'drum',\n",
       " '.',\n",
       " 'In',\n",
       " 'many',\n",
       " 'categories',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'award',\n",
       " 'caliber',\n",
       " 'stuff',\n",
       " ',',\n",
       " 'though',\n",
       " 'maybe',\n",
       " 'films',\n",
       " 'like',\n",
       " \"'The\",\n",
       " 'Departed',\n",
       " \"'\",\n",
       " 'and',\n",
       " \"'No\",\n",
       " 'Country',\n",
       " \"'\",\n",
       " 'squeezed',\n",
       " 'this',\n",
       " 'one',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'limelight',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'liked',\n",
       " 'those',\n",
       " ',',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'like',\n",
       " 'this',\n",
       " '.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(sentences[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6bdbbaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db1b8b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f3c5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c8b0fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.840B.300d.zip: 2.18GB [07:02, 5.16MB/s]                                                                                \n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████▉| 2196016/2196017 [03:14<00:00, 11308.65it/s]\n"
     ]
    }
   ],
   "source": [
    "glove = GloVe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fcfb2eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.stoi[\"n't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e13c25e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.tensor([list(torch.tensor([1, 2])), list(torch.tensor([1, 2]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "62a462f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.GloVe at 0x7f7ea41149a0>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd997979",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3420604/513005901.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGloVe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# glove_vocab = GloVe()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SentAnalysis/lib/python3.8/site-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SentAnalysis/lib/python3.8/site-packages/torchtext/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexample\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRawField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReversibleField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSubwordField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNestedField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabelField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m from .iterator import (batch, BucketIterator, Iterator, BPTTIterator,\n",
      "\u001b[0;32m~/miniconda3/envs/SentAnalysis/lib/python3.8/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SentAnalysis/lib/python3.8/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SentAnalysis/lib/python3.8/site-packages/torch/distributions/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfishersnedecor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFisherSnedecor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeometric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgumbel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGumbel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhalf_cauchy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHalfCauchy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SentAnalysis/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SentAnalysis/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SentAnalysis/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SentAnalysis/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SentAnalysis/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SentAnalysis/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "# glove_vocab = GloVe()\n",
    "sw = set(stopwords.words('english'))\n",
    "words_set = set(['<unk>'])\n",
    "itos = ['<unk>']\n",
    "stoi = {'<unk>': 0}\n",
    "indices = []\n",
    "\n",
    "mode = 'train'\n",
    "sentences_pos = []\n",
    "sentences_neg = [] \n",
    "for filename in os.listdir(os.path.join('data/aclImdb/', mode, 'pos')):\n",
    "    with open(os.path.join('data/aclImdb/', mode, 'pos', filename)) as f:\n",
    "        sentences_pos.append(f.readlines())\n",
    "for filename in os.listdir(os.path.join('data/aclImdb/', mode, 'neg')):\n",
    "    with open(os.path.join('data/aclImdb/', mode, 'neg', filename)) as f:\n",
    "        sentences_neg.append(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(dir, path_to_save, window_size=150, mode='train'):\n",
    "    indices_pos_neg = []\n",
    "    for k, sentences in enumerate([sentences_neg, sentences_pos]):\n",
    "        for l, sentence in enumerate(sentences):\n",
    "            tokenized_sentence = word_tokenize(sentence[0])\n",
    "            i, j = 0, min(window_size, len(tokenized_sentence))\n",
    "            tokenized_sentence = [w for w in tokenized_sentence if w not in sw]\n",
    "            if l%100 == 0:\n",
    "                print(len(tokenized_sentence))\n",
    "            while True:\n",
    "                s = tokenized_sentence[i:j]\n",
    "                idxs =[]\n",
    "                for word in s:\n",
    "                    if word not in glove_vocab.stoi or (word not in words_set and mode!='train'):\n",
    "                        idxs.append(0)\n",
    "                    elif word in words_set:\n",
    "                        idxs.append(stoi[word])\n",
    "                    else:\n",
    "                        itos.append(word)\n",
    "                        words_set.add(word)\n",
    "                        stoi[word] = len(itos)-1\n",
    "                        indices.append(glove.stoi[word])\n",
    "                        idxs.append(stoi[word])\n",
    "                \n",
    "                correction = 0\n",
    "                while len(idxs) < window_size//2:\n",
    "                    idxs.append(idxs[correction])\n",
    "                    correction+=1\n",
    "                    \n",
    "                while len(idxs) < window_size:\n",
    "                    idxs.append(0)\n",
    "                    \n",
    "                idxs.append(k)\n",
    "                indices_pos_neg.append(idxs)\n",
    "                \n",
    "                if len(tokenized_sentence) - j < window_size/4:\n",
    "                    break\n",
    "                if j+window_size > len(tokenized_sentence):\n",
    "                    i = len(tokenized_sentence) - window_size\n",
    "                    j = len(tokenized_sentence)\n",
    "                else:\n",
    "                    i+= window_size\n",
    "                    j+= window_size\n",
    "                \n",
    "\n",
    "    return indices_pos_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "53e9792b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "99\n",
      "441\n",
      "163\n",
      "76\n",
      "102\n",
      "237\n",
      "327\n",
      "89\n",
      "100\n",
      "55\n",
      "92\n",
      "98\n",
      "258\n",
      "472\n",
      "44\n",
      "96\n",
      "154\n",
      "641\n",
      "74\n",
      "49\n",
      "65\n",
      "125\n",
      "31\n",
      "145\n",
      "138\n",
      "126\n",
      "675\n",
      "471\n",
      "223\n",
      "174\n",
      "121\n",
      "92\n",
      "169\n",
      "101\n",
      "137\n",
      "77\n",
      "130\n",
      "92\n",
      "59\n",
      "66\n",
      "117\n",
      "142\n",
      "145\n",
      "84\n",
      "216\n",
      "229\n",
      "90\n",
      "141\n",
      "288\n",
      "99\n",
      "105\n",
      "117\n",
      "54\n",
      "214\n",
      "186\n",
      "92\n",
      "115\n",
      "315\n",
      "106\n",
      "49\n",
      "140\n",
      "250\n",
      "96\n",
      "111\n",
      "103\n",
      "140\n",
      "384\n",
      "327\n",
      "223\n",
      "95\n",
      "107\n",
      "83\n",
      "124\n",
      "397\n",
      "182\n",
      "95\n",
      "140\n",
      "80\n",
      "138\n",
      "93\n",
      "501\n",
      "215\n",
      "97\n",
      "119\n",
      "242\n",
      "94\n",
      "38\n",
      "143\n",
      "100\n",
      "236\n",
      "177\n",
      "90\n",
      "137\n",
      "85\n",
      "278\n",
      "108\n",
      "78\n",
      "32\n",
      "119\n",
      "328\n",
      "463\n",
      "450\n",
      "104\n",
      "393\n",
      "144\n",
      "97\n",
      "172\n",
      "139\n",
      "372\n",
      "118\n",
      "339\n",
      "207\n",
      "288\n",
      "164\n",
      "196\n",
      "229\n",
      "227\n",
      "566\n",
      "245\n",
      "219\n",
      "273\n",
      "212\n",
      "125\n",
      "158\n",
      "218\n",
      "151\n",
      "133\n",
      "234\n",
      "58\n",
      "192\n",
      "160\n",
      "81\n",
      "118\n",
      "265\n",
      "206\n",
      "112\n",
      "74\n",
      "116\n",
      "58\n",
      "137\n",
      "195\n",
      "141\n",
      "147\n",
      "49\n",
      "213\n",
      "135\n",
      "48\n",
      "358\n",
      "53\n",
      "90\n",
      "300\n",
      "290\n",
      "223\n",
      "376\n",
      "224\n",
      "35\n",
      "92\n",
      "60\n",
      "217\n",
      "243\n",
      "25\n",
      "68\n",
      "48\n",
      "92\n",
      "109\n",
      "149\n",
      "337\n",
      "146\n",
      "205\n",
      "129\n",
      "543\n",
      "197\n",
      "66\n",
      "165\n",
      "69\n",
      "62\n",
      "182\n",
      "227\n",
      "180\n",
      "106\n",
      "84\n",
      "148\n",
      "251\n",
      "138\n",
      "97\n",
      "132\n",
      "34\n",
      "113\n",
      "322\n",
      "479\n",
      "185\n",
      "42\n",
      "103\n",
      "99\n",
      "98\n",
      "281\n",
      "79\n",
      "223\n",
      "97\n",
      "131\n",
      "163\n",
      "97\n",
      "290\n",
      "112\n",
      "104\n",
      "94\n",
      "139\n",
      "146\n",
      "105\n",
      "195\n",
      "902\n",
      "113\n",
      "117\n",
      "753\n",
      "115\n",
      "140\n",
      "766\n",
      "272\n",
      "180\n",
      "83\n",
      "115\n",
      "176\n",
      "440\n",
      "87\n",
      "190\n",
      "480\n",
      "166\n",
      "828\n",
      "112\n",
      "221\n",
      "104\n",
      "92\n",
      "93\n",
      "126\n",
      "323\n",
      "38\n",
      "89\n",
      "85\n",
      "126\n",
      "128\n",
      "54\n",
      "88\n",
      "132\n",
      "227\n",
      "533\n",
      "453\n",
      "87\n",
      "193\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "indices_pos_neg = tokenize_data('data/aclImdb/', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e48f466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(indices_pos_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7392795c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>41</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>41</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>155</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>160</td>\n",
       "      <td>63</td>\n",
       "      <td>55</td>\n",
       "      <td>41</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>51</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>218</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>219</td>\n",
       "      <td>128</td>\n",
       "      <td>220</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212</td>\n",
       "      <td>222</td>\n",
       "      <td>16</td>\n",
       "      <td>62</td>\n",
       "      <td>28</td>\n",
       "      <td>55</td>\n",
       "      <td>223</td>\n",
       "      <td>224</td>\n",
       "      <td>225</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>262</td>\n",
       "      <td>263</td>\n",
       "      <td>264</td>\n",
       "      <td>265</td>\n",
       "      <td>6</td>\n",
       "      <td>266</td>\n",
       "      <td>267</td>\n",
       "      <td>268</td>\n",
       "      <td>269</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>308</td>\n",
       "      <td>16</td>\n",
       "      <td>309</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37805</th>\n",
       "      <td>8306</td>\n",
       "      <td>23565</td>\n",
       "      <td>23566</td>\n",
       "      <td>465</td>\n",
       "      <td>14374</td>\n",
       "      <td>55</td>\n",
       "      <td>16612</td>\n",
       "      <td>55</td>\n",
       "      <td>2418</td>\n",
       "      <td>1826</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37806</th>\n",
       "      <td>1940</td>\n",
       "      <td>160</td>\n",
       "      <td>112</td>\n",
       "      <td>55</td>\n",
       "      <td>41</td>\n",
       "      <td>1812</td>\n",
       "      <td>2199</td>\n",
       "      <td>5915</td>\n",
       "      <td>5291</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>998</td>\n",
       "      <td>42986</td>\n",
       "      <td>2252</td>\n",
       "      <td>55</td>\n",
       "      <td>75195</td>\n",
       "      <td>880</td>\n",
       "      <td>2087</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37807</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>271</td>\n",
       "      <td>...</td>\n",
       "      <td>1318</td>\n",
       "      <td>1318</td>\n",
       "      <td>12211</td>\n",
       "      <td>55</td>\n",
       "      <td>159</td>\n",
       "      <td>16</td>\n",
       "      <td>2054</td>\n",
       "      <td>3081</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37808</th>\n",
       "      <td>50</td>\n",
       "      <td>253</td>\n",
       "      <td>2798</td>\n",
       "      <td>9734</td>\n",
       "      <td>1608</td>\n",
       "      <td>5758</td>\n",
       "      <td>1150</td>\n",
       "      <td>66</td>\n",
       "      <td>597</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37809</th>\n",
       "      <td>55</td>\n",
       "      <td>2369</td>\n",
       "      <td>510</td>\n",
       "      <td>12220</td>\n",
       "      <td>14161</td>\n",
       "      <td>2634</td>\n",
       "      <td>22069</td>\n",
       "      <td>1890</td>\n",
       "      <td>1751</td>\n",
       "      <td>1150</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>38305</td>\n",
       "      <td>303</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37810 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4     5      6     7     8     9    ...  \\\n",
       "0         1      2      3      4      5     6      7     8     9    10  ...   \n",
       "1        60     61     62     63     64    41     65    66    41    67  ...   \n",
       "2       158    159    160     63     55    41     70    71    51   112  ...   \n",
       "3       212    222     16     62     28    55    223   224   225   223  ...   \n",
       "4        41    262    263    264    265     6    266   267   268   269  ...   \n",
       "...     ...    ...    ...    ...    ...   ...    ...   ...   ...   ...  ...   \n",
       "37805  8306  23565  23566    465  14374    55  16612    55  2418  1826  ...   \n",
       "37806  1940    160    112     55     41  1812   2199  5915  5291    64  ...   \n",
       "37807     8      9     10     11      8     9     10    11    12   271  ...   \n",
       "37808    50    253   2798   9734   1608  5758   1150    66   597    16  ...   \n",
       "37809    55   2369    510  12220  14161  2634  22069  1890  1751  1150  ...   \n",
       "\n",
       "        141   142    143   144  145    146    147   148  149  150  \n",
       "0         0     0      0     0    0      0      0     0    0    0  \n",
       "1       155   156    157    16    0      0      0     0    0    0  \n",
       "2        11    12    218    62   55    219    128   220  221    0  \n",
       "3         0     0      0     0    0      0      0     0    0    0  \n",
       "4         9    10     11   308   16    309      8     9   10    0  \n",
       "...     ...   ...    ...   ...  ...    ...    ...   ...  ...  ...  \n",
       "37805     0     0      0     0    0      0      0     0    0    1  \n",
       "37806    16   998  42986  2252   55  75195    880  2087    0    1  \n",
       "37807  1318  1318  12211    55  159     16   2054  3081   55    1  \n",
       "37808     8     9     10    11   41     38     51    55   26    1  \n",
       "37809    10    11      8     9   10     11  38305   303   16    1  \n",
       "\n",
       "[37810 rows x 151 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "977b76a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "37805    1\n",
       "37806    1\n",
       "37807    1\n",
       "37808    1\n",
       "37809    1\n",
       "Name: 150, Length: 37810, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[150] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f45f88e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18670"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[150].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4fa992cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", 'r') as f: \n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4ea6519f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'window_size': 150, 'data_dir': 'data/aclImdb/', 'embedding_dim': 300}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['DATASET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "03471ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "74794f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "        \"itos\": itos,\n",
    "        \"stoi\": stoi,\n",
    "        \"vectors\": torch.cat([torch.ones(1, 300), glove.vectors[indices]], 0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "56bdebe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97042"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab[\"itos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb956e",
   "metadata": {},
   "source": [
    "## Tests with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9c963eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "065b72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SentimentAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82e80982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"config.json\", 'r') as f: \n",
    "    config = json.load(f)['MODEL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa3b5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out_channels': 40,\n",
       " 'n_blocks': 2,\n",
       " 'hidden_dim': 32,\n",
       " 'num_layers': 2,\n",
       " 'dropout': 0.2,\n",
       " 'bidirectional': True,\n",
       " 'linear_dim': 100}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21af324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open(\"data/vocab\", 'rb') as f: \n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "016ebe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpufs/users/students/iasd22/iasd22_0899/miniconda3/envs/SentAnalysis/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = SentimentAnalysis(vocab=vocab, \n",
    "                          out_channels=20,\n",
    "                          n_blocks=1, \n",
    "                          hidden_dim=16, \n",
    "                          num_layers=1,\n",
    "                          dropout=config[\"dropout\"], \n",
    "                          bidirectional=False, \n",
    "                          linear_dim=config[\"linear_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "633b00f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inpt = torch.randint(0, 90000, (32, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46315b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 150])\n",
      "torch.Size([32, 300, 150])\n",
      "torch.Size([32, 75, 60])\n",
      "torch.Size([1, 32, 16])\n",
      "torch.Size([1, 32, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inpt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f3266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SentAnalysis",
   "language": "python",
   "name": "sentanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
